{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f351f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b9a83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data into dataframes\n",
    "zones = pd.read_csv(r\"C:\\Users\\jmsav\\root\\git\\savirame\\oubt\\taxi_zone_lookup.csv\")\n",
    "trips = pd.read_parquet(r\"C:\\Users\\jmsav\\root\\git\\savirame\\oubt\\yellow_tripdata_2025-08.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a34d885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LocationID        Borough                     Zone service_zone\n",
      "0           1            EWR           Newark Airport          EWR\n",
      "1           2         Queens              Jamaica Bay    Boro Zone\n",
      "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
      "3           4      Manhattan            Alphabet City  Yellow Zone\n",
      "4           5  Staten Island            Arden Heights    Boro Zone\n",
      "5           6  Staten Island  Arrochar/Fort Wadsworth    Boro Zone\n",
      "6           7         Queens                  Astoria    Boro Zone\n",
      "7           8         Queens             Astoria Park    Boro Zone\n",
      "8           9         Queens               Auburndale    Boro Zone\n",
      "9          10         Queens             Baisley Park    Boro Zone\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265 entries, 0 to 264\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   LocationID    265 non-null    int64 \n",
      " 1   Borough       264 non-null    object\n",
      " 2   Zone          264 non-null    object\n",
      " 3   service_zone  263 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3574091 entries, 0 to 3574090\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int32         \n",
      " 8   DOLocationID           int32         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  Airport_fee            float64       \n",
      " 19  cbd_congestion_fee     float64       \n",
      "dtypes: datetime64[us](2), float64(13), int32(3), int64(1), object(1)\n",
      "memory usage: 504.5+ MB\n",
      "None\n",
      "Borough\n",
      "Queens           69\n",
      "Manhattan        69\n",
      "Brooklyn         61\n",
      "Bronx            43\n",
      "Staten Island    20\n",
      "EWR               1\n",
      "Unknown           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(zones.head(10))\n",
    "print(zones.info())\n",
    "print(trips.info())\n",
    "print(zones['Borough'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327ffb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ZONE MASTER: 265 records\n",
      "   Columns: ['LocationID', 'Borough', 'Zone', 'service_zone']\n"
     ]
    }
   ],
   "source": [
    "# Analyze Zone Master Data\n",
    "print(f\"\\n1. ZONE MASTER: {len(zones)} records\")\n",
    "print(f\"   Columns: {list(zones.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6525a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. REFERENCE DATA:\n",
      "   - VendorIDs: [1, 2, 6, 7]\n",
      "   - RateCodes: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 99.0]\n",
      "   - PaymentTypes: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Identify Reference Data\n",
    "print(f\"\\n2. REFERENCE DATA:\")\n",
    "print(f\"   - VendorIDs: {sorted(trips['VendorID'].unique())}\")\n",
    "print(f\"   - RateCodes: {sorted(trips['RatecodeID'].dropna().unique())}\")\n",
    "print(f\"   - PaymentTypes: {sorted(trips['payment_type'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be1770d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. TRANSACTIONAL DATA:\n",
      "   - Trip Records: 3,574,091\n"
     ]
    }
   ],
   "source": [
    "# Transactional Data\n",
    "print(f\"\\n3. TRANSACTIONAL DATA:\")\n",
    "print(f\"   - Trip Records: {len(trips):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e81e3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFOR each record A in dataset:\\n    FOR each record B in dataset:\\n        IF A.id â‰  B.id AND\\n           normalize(A.Zone) == normalize(B.Zone) AND\\n           normalize(A.Borough) == normalize(B.Borough):\\n        THEN\\n           mark A and B as duplicates\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple matching alogirthm to detect duplicates\n",
    "'''\n",
    "FOR each record A in dataset:\n",
    "    FOR each record B in dataset:\n",
    "        IF A.id â‰  B.id AND\n",
    "           normalize(A.Zone) == normalize(B.Zone) AND\n",
    "           normalize(A.Borough) == normalize(B.Borough):\n",
    "        THEN\n",
    "           mark A and B as duplicates\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63e465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fc9d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DUPLICATE RECORDS DETECTED ---\n",
      "     LocationID    Borough                                           Zone  \\\n",
      "55           56     Queens                                         Corona   \n",
      "56           57     Queens                                         Corona   \n",
      "102         103  Manhattan  Governor's Island/Ellis Island/Liberty Island   \n",
      "103         104  Manhattan  Governor's Island/Ellis Island/Liberty Island   \n",
      "104         105  Manhattan  Governor's Island/Ellis Island/Liberty Island   \n",
      "\n",
      "    service_zone  \n",
      "55     Boro Zone  \n",
      "56     Boro Zone  \n",
      "102  Yellow Zone  \n",
      "103  Yellow Zone  \n",
      "104  Yellow Zone  \n",
      "\n",
      "Original count: 265\n",
      "Cleaned count: 262\n"
     ]
    }
   ],
   "source": [
    "# normalize text columns\n",
    "# 1. Detect exact duplicates (Zone + Borough)\n",
    "exact_duplicates = zones[\n",
    "    zones.duplicated(subset=['Zone', 'Borough'], keep=False)\n",
    "]\n",
    "\n",
    "print(\"--- DUPLICATE RECORDS DETECTED ---\")\n",
    "print(exact_duplicates.sort_values(by='Zone'))\n",
    "\n",
    "# 2. Create Golden Record (keep first occurrence)\n",
    "zones_master_clean = zones.drop_duplicates(\n",
    "    subset=['Zone', 'Borough'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# 3. Save the cleaned master data\n",
    "zones_master_clean.to_csv('cleaned_taxi_zones.csv', index=False)\n",
    "\n",
    "print(f\"\\nOriginal count: {len(zones)}\")\n",
    "print(f\"Cleaned count: {len(zones_master_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98cd07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Duplicates Found: 5\n",
      "Top Fuzzy Matches: [('Bensonhurst East', 'Bensonhurst West', 0.875), ('Bushwick North', 'Bushwick South', 0.857), ('Crown Heights North', 'Crown Heights South', 0.895), ('East Harlem North', 'East Harlem South', 0.882), ('Financial District North', 'Financial District South', 0.917)]\n"
     ]
    }
   ],
   "source": [
    "# 4. Fuzzy Match: Compare all unique zone names\n",
    "unique_zones = zones_master_clean['Zone'].dropna().unique().tolist()\n",
    "fuzzy_matches = []\n",
    "\n",
    "for z1, z2 in itertools.combinations(unique_zones, 2):\n",
    "    score = SequenceMatcher(None, z1, z2).ratio()\n",
    "    # 0.85 is a high similarity threshold\n",
    "    if 0.85 <= score < 1.0:\n",
    "        fuzzy_matches.append((z1, z2, round(score, 3)))\n",
    "\n",
    "# Output results\n",
    "print(\"Exact Duplicates Found:\", len(exact_duplicates))\n",
    "print(\"Top Fuzzy Matches:\", fuzzy_matches[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9eaa951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REFERENTIAL INTEGRITY REPORT ---\n",
      "âŒ ALERT: Found 1 orphaned LocationIDs!\n",
      "Orphaned IDs: {57}\n",
      "\n",
      "Total Unique Zones in Transactions: 261\n",
      "Total Golden Records in Master: 262\n",
      "Unused Master Zones (No trips recorded): 2\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the \"Golden\" Master Data\n",
    "master_df = zones_master_clean\n",
    "master_ids = set(master_df['LocationID'].unique())\n",
    "\n",
    "# 2. Load the Transaction Data (Parquet)\n",
    "# We only need the Location columns to save memory\n",
    "transactions = trips[['PULocationID', 'DOLocationID']].copy()\n",
    "\n",
    "\n",
    "# 3. Extract unique IDs from Transactions\n",
    "pickup_ids = set(transactions['PULocationID'].unique())\n",
    "dropoff_ids = set(transactions['DOLocationID'].unique())\n",
    "all_transaction_ids = pickup_ids.union(dropoff_ids)\n",
    "\n",
    "# 4. FIND THE ORPHANS (In Transactions but NOT in Master)\n",
    "orphans = all_transaction_ids - master_ids\n",
    "\n",
    "# 5. FIND UNUSED MASTER DATA (In Master but NOT in Transactions)\n",
    "unused = master_ids - all_transaction_ids\n",
    "\n",
    "print(\"--- REFERENTIAL INTEGRITY REPORT ---\")\n",
    "if not orphans:\n",
    "    print(\"âœ… SUCCESS: No orphaned records found. All trips map to valid zones.\")\n",
    "else:\n",
    "    print(f\"âŒ ALERT: Found {len(orphans)} orphaned LocationIDs!\")\n",
    "    print(f\"Orphaned IDs: {orphans}\")\n",
    "    \n",
    "print(f\"\\nTotal Unique Zones in Transactions: {len(all_transaction_ids)}\")\n",
    "print(f\"Total Golden Records in Master: {len(master_ids)}\")\n",
    "print(f\"Unused Master Zones (No trips recorded): {len(unused)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ab00f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boroughs_df:\n",
      "    borough_name\n",
      "0          Bronx\n",
      "1       Brooklyn\n",
      "2            EWR\n",
      "3      Manhattan\n",
      "4         Queens\n",
      "5  Staten Island\n",
      "6        Unknown\n",
      "\n",
      "service_zones_df:\n",
      "  service_zone_name\n",
      "0          Airports\n",
      "1         Boro Zone\n",
      "2               EWR\n",
      "3       Yellow Zone\n",
      "\n",
      "zones_for_db (Golden Records):\n",
      "   location_id                zone_name        borough service_zone\n",
      "0            1           Newark Airport            EWR          EWR\n",
      "1            2              Jamaica Bay         Queens    Boro Zone\n",
      "2            3  Allerton/Pelham Gardens          Bronx    Boro Zone\n",
      "3            4            Alphabet City      Manhattan  Yellow Zone\n",
      "4            5            Arden Heights  Staten Island    Boro Zone\n",
      "5            6  Arrochar/Fort Wadsworth  Staten Island    Boro Zone\n",
      "6            7                  Astoria         Queens    Boro Zone\n",
      "7            8             Astoria Park         Queens    Boro Zone\n",
      "8            9               Auburndale         Queens    Boro Zone\n",
      "9           10             Baisley Park         Queens    Boro Zone\n",
      "\n",
      "Total: 262 golden records\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PREPARE MASTER DATA DataFrames FOR RDS\n",
    "# ============================================\n",
    "\n",
    "# 1. BOROUGHS - Extract unique boroughs\n",
    "unique_boroughs = sorted(zones_master_clean['Borough'].dropna().unique())\n",
    "boroughs_df = pd.DataFrame({\n",
    "    'borough_name': unique_boroughs\n",
    "})\n",
    "print(\"boroughs_df:\")\n",
    "print(boroughs_df)\n",
    "\n",
    "# 2. SERVICE ZONES - Extract unique service zones\n",
    "unique_service_zones = sorted(zones_master_clean['service_zone'].dropna().unique())\n",
    "service_zones_df = pd.DataFrame({\n",
    "    'service_zone_name': unique_service_zones\n",
    "})\n",
    "print(\"\\nservice_zones_df:\")\n",
    "print(service_zones_df)\n",
    "\n",
    "# 3. ZONES (Golden Records) - Main master table\n",
    "zones_for_db = zones_master_clean.rename(columns={\n",
    "    'LocationID': 'location_id',\n",
    "    'Zone': 'zone_name',\n",
    "    'Borough': 'borough',\n",
    "    'service_zone': 'service_zone'\n",
    "})\n",
    "zones_for_db = zones_for_db[['location_id', 'zone_name', 'borough', 'service_zone']]\n",
    "\n",
    "print(\"\\nzones_for_db (Golden Records):\")\n",
    "print(zones_for_db.head(10))\n",
    "print(f\"\\nTotal: {len(zones_for_db)} golden records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2018858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to RDS PostgreSQL\n",
      "âœ… Schema 'mdm' created\n",
      "  âœ… mdm.boroughs: 7 records\n",
      "  âœ… mdm.service_zones: 4 records\n",
      "  âœ… mdm.zones: 262 records\n",
      "\n",
      "ðŸ“Š Table Record Counts:\n",
      "   mdm.boroughs: 7\n",
      "   mdm.service_zones: 4\n",
      "   mdm.zones: 262\n",
      "\n",
      "ðŸŽ‰ All master data tables created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SIMPLIFIED: Build Master Data Tables in RDS\n",
    "# (Auto-creates tables from DataFrame structure)\n",
    "# ============================================\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# RDS Configuration - Replace with your values\n",
    "RDS_CONFIG = {\n",
    "    'host': 'mdm-postgres.cqre4gyo8nft.us-east-1.rds.amazonaws.com',  # Fixed: added closing quote\n",
    "    'port': 5432,\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',       # TODO: Add your username\n",
    "    'password':'savitha1'\n",
    "}\n",
    "\n",
    "# Build connection string\n",
    "CONNECTION_STRING = (\n",
    "    f\"postgresql://{RDS_CONFIG['user']}:{RDS_CONFIG['password']}\"\n",
    "    f\"@{RDS_CONFIG['host']}:{RDS_CONFIG['port']}/{RDS_CONFIG['database']}\"\n",
    ")\n",
    "\n",
    "def build_mdm_tables_in_rds():\n",
    "    \"\"\"\n",
    "    Build all master data tables in RDS PostgreSQL.\n",
    "    Tables are auto-created from DataFrame structure - no manual DDL needed!\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Create engine\n",
    "    engine = create_engine(CONNECTION_STRING)\n",
    "    \n",
    "    # 2. Test connection\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "        print(\"âœ… Connected to RDS PostgreSQL\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Connection failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Create schema (only thing we need DDL for)\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS mdm\"))\n",
    "        conn.commit()\n",
    "    print(\"âœ… Schema 'mdm' created\")\n",
    "    \n",
    "    # 4. Load all tables - to_sql auto-creates tables from DataFrame!\n",
    "    tables = {\n",
    "        'boroughs': boroughs_df,\n",
    "        'service_zones': service_zones_df,\n",
    "        'zones': zones_for_db  # Golden records\n",
    "    }\n",
    "    \n",
    "    for table_name, df in tables.items():\n",
    "        df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            schema='mdm',\n",
    "            if_exists='replace',  # Drops & recreates table automatically\n",
    "            index=False\n",
    "        )\n",
    "        print(f\"  âœ… mdm.{table_name}: {len(df)} records\")\n",
    "    \n",
    "    # 5. Verify\n",
    "    print(\"\\nðŸ“Š Table Record Counts:\")\n",
    "    for table_name in tables.keys():\n",
    "        count = pd.read_sql(f\"SELECT COUNT(*) FROM mdm.{table_name}\", engine).iloc[0, 0]\n",
    "        print(f\"   mdm.{table_name}: {count}\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ All master data tables created successfully!\")\n",
    "    return engine\n",
    "\n",
    "# Execute\n",
    "engine = build_mdm_tables_in_rds()  # Uncomment when RDS is configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2aa671f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   location_id                zone_name        borough service_zone\n",
      "0            1           Newark Airport            EWR          EWR\n",
      "1            2              Jamaica Bay         Queens    Boro Zone\n",
      "2            3  Allerton/Pelham Gardens          Bronx    Boro Zone\n",
      "3            4            Alphabet City      Manhattan  Yellow Zone\n",
      "4            5            Arden Heights  Staten Island    Boro Zone\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\n",
    "    \"SELECT * FROM mdm.zones LIMIT 5\",\n",
    "    engine\n",
    ")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861efe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
